
# ðŸŽ¨ Fine-tuning text-to-image diffusion models for personalization and subject-driven generation
### Presentation: [Personalization of Diffusion Models with ðŸ§¨Diffusers](https://docs.google.com/presentation/d/1m-ZaXuB0dDcg77EUaS6cnDaYED89JYviYv-fYRvu8yU/edit?usp=sharing)

## Workshop description
During the workshop you will get familiar with different fine-tuning techniques for text-to-image models, and learn how to easily teach a diffusion model a concept of your choosing  (special style, a pet, faces etc) with as little as 3 images depicting your concept. 

## Requirements
Do not forget to indicate Python version and any other tools
+ add requirements.txt or conda.yml or docker image or Binder/Google Collab link

## Usage
* Clone the repository
* Start { TOOL } and navigate to the workshop folder

## Video record
Re-watch [this YouTube stream](https://www.youtube.com/live/f9FWJ9UjZ-U)

## Credits
This workshop was set up by @pyladiesams and @linoytsaban
